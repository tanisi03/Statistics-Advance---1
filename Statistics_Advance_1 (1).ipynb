{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1 Explain the properties of the F-distribution."
      ],
      "metadata": {
        "id": "DDnWV2cK605s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ans. Properties of the F-distribution\n",
        "\n",
        "1. Right-Skewed: The F-distribution is positively skewed, meaning it has a longer tail on the right. It starts at 0 and extends to infinity.\n",
        "\n",
        "2. Non-negative: F-values are always non-negative (≥ 0) because they represent a ratio of variances, which cannot be negative.\n",
        "\n",
        "3. Depends on Degrees of Freedom: The shape of the F-distribution is determined by two degrees of freedom: one for the numerator (between-group variance) and one for the denominator (within-group variance).\n",
        "\n",
        "~As the degrees of freedom increase, the distribution becomes less skewed and approaches a normal distribution.\n",
        "\n",
        "4. Used for Comparing Variances:The F-distribution is used in tests like ANOVA to compare variances between two or more groups\n",
        "\n",
        "5. Hypothesis Testing:The F-statistic compares the variances of groups. A large F-statistic suggests significant differences, while a small F-statistic suggests no difference.\n",
        "\n",
        "6. Critical Values and P-values:The F-distribution is used to calculate p-values and critical values in hypothesis tests. If the computed F-statistic exceeds the critical value, we reject the null hypothesis.\n"
      ],
      "metadata": {
        "id": "AK4-uJbo66zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
      ],
      "metadata": {
        "id": "Uig6NDHs8VGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The F-distribution is used in the following statistical tests\n",
        "\n",
        "1. Analysis of Variance (ANOVA): To compare means across multiple groups by testing the ratio of between-group variance to within-group variance. The F-distribution is appropriate because it models the ratio of variances.\n",
        "\n",
        "2. F-test for Comparing Two Variances: To test if two population variances are equal. The F-statistic is the ratio of the two sample variances and follows an F-distribution under the null hypothesis.\n",
        "\n",
        "3. Regression Analysis (F-test for Model Significance): To assess the overall significance of a regression model, by comparing the explained variance to the unexplained variance. The F-distribution is used because it models the ratio of mean squares in regression.\n",
        "\n",
        "4. Regression Analysis (F-test for Model Significance): To assess the overall significance of a regression model, by comparing the explained variance to the unexplained variance. The F-distribution is used because it models the ratio of mean squares in regression.\n",
        "\n",
        "**Why It's Appropriate:**\n",
        "\n",
        "The F-distribution is used in these tests because it describes the ratio of two variances (or mean squares), and these tests are concerned with comparing variances, which is exactly what the F-distribution models."
      ],
      "metadata": {
        "id": "stL8PawP8cjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What are the key assumptions required for conducting an F-test to compare the variances of two\n",
        "populations?"
      ],
      "metadata": {
        "id": "EKQ8SVyi9TRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. For an F-test to compare the variances of two populations, the following key assumptions must be met:\n",
        "\n",
        "1. Independence: The two samples must be independent of each other.\n",
        "\n",
        "2. Normality: Both populations (or the samples) should follow a normal distribution. This assumption is important because the F-distribution arises from the ratio of two chi-squared distributions, which are based on normality.\n",
        "\n",
        "3. Normality: Both populations (or the samples) should follow a normal distribution. This assumption is important because the F-distribution arises from the ratio of two chi-squared distributions, which are based on normality.\n",
        "\n",
        "These assumptions ensure the validity of the F-test and the accuracy of the results."
      ],
      "metadata": {
        "id": "H6KbKQK99Z5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is the purpose of ANOVA, and how does it differ from a t-test?"
      ],
      "metadata": {
        "id": "7nIt36yT96so"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Ans . **Purpose of ANOVA:**\n",
        "ANOVA (Analysis of Variance) is a statistical technique used to compare the means of three or more groups to determine if there is a significant difference among them. It tests the null hypothesis that all group means are equal. ANOVA works by analyzing the variance within each group and between the groups.\n",
        "\n",
        "**How ANOVA Differs from a t-test:**\n",
        "\n",
        "1. Number of Groups:\n",
        "~ T-test: Compares the means of two groups to see if they are significantly different from each other.\n",
        "\n",
        "~ANOVA: Compares the means of three or more groups to check if at least one group mean differs significantly from the others.\n",
        "\n",
        "2. Hypothesis Testing:\n",
        "\n",
        "~ T-test: Tests whether the difference between two group means is statistically significant.\n",
        "\n",
        "~ANOVA: Tests whether there are any significant differences among the means of multiple groups. If ANOVA indicates a significant difference, follow-up tests (like Tukey's HSD) are used to identify which specific groups are different.\n",
        "\n",
        "3. Type of Test:\n",
        "\n",
        "~ T-test: Relies on comparing the difference in means and the standard error of the difference for two groups.\n",
        "\n",
        "~ANOVA: Uses variance analysis by comparing the variability between groups (between-group variance) to the variability within groups (within-group variance).\n",
        "\n",
        "**Key Difference:**\n",
        "While the t-test is limited to comparing two groups, ANOVA extends the comparison to three or more groups, making it more versatile for situations involving multiple groups."
      ],
      "metadata": {
        "id": "GWoQV29s-EGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
        "than two groups."
      ],
      "metadata": {
        "id": "mh3Kh0pkAYdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. **When to Use One-Way ANOVA Instead of Multiple t-tests:**\n",
        "Use a One-Way ANOVA when you are comparing the means of three or more groups and want to test if at least one of the group means is significantly different from the others.\n",
        "\n",
        "**Why One-Way ANOVA is Preferred Over Multiple t-tests:**\n",
        "\n",
        "1. Control of Type I Error:\n",
        "\n",
        "~ When you conduct multiple t-tests, each test carries a chance of making a Type I error (incorrectly rejecting the null hypothesis). The more t-tests you run, the higher the cumulative probability of a false positive.\n",
        "\n",
        "~One-Way ANOVA controls the overall Type I error rate by testing all group means simultaneously. It evaluates the variance between all groups in one test, reducing the chance of making an error by chance.\n",
        "\n",
        "2.Efficiency:\n",
        "\n",
        "~ANOVA tests all group comparisons in one analysis, while multiple t-tests require separate comparisons between pairs of groups. This makes ANOVA more efficient, particularly with large numbers of groups.\n",
        "\n",
        "3.Comprehensive Testing:\n",
        "\n",
        "~One-Way ANOVA tests if there are any significant differences among all groups. Multiple t-tests only test specific pairs of groups and cannot tell you if there is an overall difference across all groups.\n",
        "\n",
        "~ANOVA provides a single test statistic (F-statistic) to assess the overall difference, and if significant, follow-up tests (e.g., Tukey's HSD) can identify which specific groups differ.\n",
        "\n",
        "**Summary:**\n",
        "One-Way ANOVA is preferred when comparing three or more groups because it reduces the risk of Type I error, is more efficient, and provides a comprehensive analysis of group differences in one step, while multiple t-tests are more error-prone and less efficient for multiple comparisons."
      ],
      "metadata": {
        "id": "VWs7r8H5Advz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
        "How does this partitioning contribute to the calculation of the F-statistic?"
      ],
      "metadata": {
        "id": "3959WgN7BypQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ans. In ANOVA (Analysis of Variance), the total variance in the data is divided into two parts:\n",
        "\n",
        "~ Between-Group Variance: This reflects the variability caused by differences between the group means. If the group means are widely spread out, the between-group variance will be large, suggesting that the groups differ significantly from one another.\n",
        "\n",
        "~ Within-Group Variance: This represents the variability within each group, or how individual data points vary from their own group mean. High within-group variance indicates more variation within each group, often due to random factors or inherent variability in the data.\n",
        "\n",
        "**Contribution to the F-statistic:**\n",
        "\n",
        "Contribution to the F-statistic:\n",
        "\n",
        "~A large F-statistic (high between-group variance relative to within-group variance) indicates that the group means differ more than would be expected by random chance, suggesting a significant effect.\n",
        "\n",
        "~A small F-statistic (low between-group variance relative to within-group variance) suggests that any observed differences between the group means are likely due to random variation, and not a true difference.\n",
        "\n",
        "In summary, the partitioning of variance helps determine whether the variability between groups is large enough relative to the variability within groups to justify concluding that the group means are different. The F-statistic quantifies this by comparing the two types of variance."
      ],
      "metadata": {
        "id": "NJW7p6xgCJRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key\n",
        "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
      ],
      "metadata": {
        "id": "W_U77nVpDE_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. **Key Differences Between Classical (Frequentist) and Bayesian Approaches to ANOVA:**\n",
        "\n",
        "1. Handling Uncertainty:\n",
        "\n",
        "~Frequentist: Uncertainty is quantified using p-values and confidence intervals based on sampling distributions. The true parameters are considered fixed but unknown.\n",
        "\n",
        "~Bayesian: Uncertainty is represented as probability distributions over parameters (posterior distributions), which update as more data is observed. Parameters are treated as random variables.\n",
        "\n",
        "2. Parameter Estimation:\n",
        "\n",
        "~Frequentist: Estimates are point estimates (e.g., sample means), with uncertainty reflected in confidence intervals.\n",
        "\n",
        "~Bayesian: Parameters have probability distributions (posterior), reflecting uncertainty about parameter values, and providing a range of plausible values rather than just a single estimate.\n",
        "\n",
        "3. Hypothesis Testing:\n",
        "\n",
        "~Frequentist: Hypothesis testing relies on a null hypothesis, using p-values to decide whether to reject it. Decisions are binary (reject or fail to reject).\n",
        "\n",
        "~Bayesian: Hypothesis testing is based on posterior probabilities and Bayes factors, comparing the likelihood of different hypotheses or models. It provides a measure of evidence for each hypothesis.\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "~Frequentist: Focuses on testing specific hypotheses and estimating parameters with point estimates and confidence intervals, using p-values for decision-making.\n",
        "\n",
        "~Bayesian: Provides a more flexible approach with probability distributions over parameters, incorporating prior knowledge and offering probabilistic interpretation of results."
      ],
      "metadata": {
        "id": "ct_uzUKYDMjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Question: You have two sets of data representing the incomes of two different professions1\n",
        "~Profession A: [48, 52, 55, 60, 62'\n",
        "~Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
      ],
      "metadata": {
        "id": "PHwjmbE3Ej4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use Python to calculate the F-statistic and p-value for this test using the SciPy library.\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for the two professions\n",
        "profession_A = [48, 52, 55, 60, 62]\n",
        "profession_B = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Calculate the sample variances\n",
        "var_A = np.var(profession_A, ddof=1)  # ddof=1 for sample variance\n",
        "var_B = np.var(profession_B, ddof=1)\n",
        "\n",
        "# Calculate the F-statistic (larger variance / smaller variance)\n",
        "F_statistic = var_A / var_B if var_A >= var_B else var_B / var_A\n",
        "\n",
        "# Degrees of freedom for each sample\n",
        "df_A = len(profession_A) - 1  # df = n - 1 for sample variance\n",
        "df_B = len(profession_B) - 1\n",
        "\n",
        "# Perform the F-test using the F-distribution\n",
        "p_value = 2 * min(stats.f.cdf(F_statistic, df_A, df_B), 1 - stats.f.cdf(F_statistic, df_A, df_B))\n",
        "\n",
        "# Display the results\n",
        "print(f\"Variance of Profession A: {var_A}\")\n",
        "print(f\"Variance of Profession B: {var_B}\")\n",
        "print(f\"F-statistic: {F_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Conclusion\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The variances are equal.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGqAKCdDFuoA",
        "outputId": "8cf64aad-18df-40ff-828f-de13f4bb94c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of Profession A: 32.8\n",
            "Variance of Profession B: 15.7\n",
            "F-statistic: 2.089171974522293\n",
            "P-value: 0.49304859900533904\n",
            "Fail to reject the null hypothesis: The variances are equal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "1. Data: The incomes for two professions are provided as two lists (profession_A and profession_B).\n",
        "2. Variances: The sample variances for each profession are computed using np.var() with ddof=1 (for sample variance).\n",
        "3. F-statistic: The F-statistic is the ratio of the larger variance to the smaller variance.\n",
        "4. P-value: The stats.f.cdf() function computes the cumulative distribution function (CDF) for the 5. 5. 5 F-distribution, and we calculate the p-value using both tails of the distribution.\n",
        "5. Hypothesis Testing: Based on the p-value, we compare it to the significance level (α = 0.05) and decide whether to reject the null hypothesis."
      ],
      "metadata": {
        "id": "5tTyeA3tGDvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "average heights between three different regions with the following data1\n",
        "~ Region A: [160, 162, 165, 158, 164'\n",
        "~ Region B: [172, 175, 170, 168, 174'\n",
        "~ Region C: [180, 182, 179, 185, 183'\n",
        "~ Task: Write Python code to perform the one-way ANOVA and interpret the results.\n",
        "~ Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
      ],
      "metadata": {
        "id": "XarAQd08GTvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Ans . ~ Region A: [160, 162, 165, 158, 164]\n",
        "\n",
        "~ Region B: [172, 175, 170, 168, 174]\n",
        "\n",
        "~ Region C: [180, 182, 179, 185, 183]\n",
        "\n",
        "~ Task: Write Python code to perform the one-way ANOVA and interpret the results.\n",
        "\n",
        "~ Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
      ],
      "metadata": {
        "id": "n-tf4opgGoLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''To perform a one-way ANOVA to test whether there are statistically significant differences in average\n",
        "   heights between the three regions, we can use Python's SciPy library.'''\n",
        "# The one-way ANOVA tests the null hypothesis that the means of the three groups (regions) are equal.\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for the three regions\n",
        "region_A = [160, 162, 165, 158, 164]\n",
        "region_B = [172, 175, 170, 168, 174]\n",
        "region_C = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
        "\n",
        "# Display the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Conclusion\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in mean heights.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in mean heights.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi1Q5F4VG2Rs",
        "outputId": "52230358-e710-4f9b-bf67-823c30b4c2c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.87330316742101\n",
            "P-value: 2.870664187937026e-07\n",
            "Reject the null hypothesis: There is a significant difference in mean heights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "1. Data: We have the height data for three regions: Region A, Region B, and Region C.\n",
        "\n",
        "2. stats.f_oneway(): This function from the SciPy library performs the one-way ANOVA. It returns the F-statistic and the p-value.\n",
        "\n",
        "3. Interpretation:\n",
        "\n",
        "~ If p-value < 0.05, we reject the null hypothesis, indicating a significant difference in the means of at least one of the regions.\n",
        "\n",
        "~ If p-value ≥ 0.05, we fail to reject the null hypothesis, indicating no significant difference in the means of the regions."
      ],
      "metadata": {
        "id": "K1lfK824HF_m"
      }
    }
  ]
}